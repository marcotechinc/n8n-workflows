{
  "name": "PromptOS-ParallelGen-Vote",
  "nodes": [
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.prompt }}\n\nRespond in this JSON format:\n\n{\n  \"text_llm_generation_b\": \"<your answer>\",\n  \"scorecard\": {\n    \"clarity\": 1–5,\n    \"relevance\": 1–5,\n    \"insightfulness\": 1–5,\n    \"actionability\": 1–5\n  }\n}\n\nAfter responding, evaluate your own output honestly. Be fair and self-critical — reserve 5s for excellent quality only.",
        "hasOutputParser": true,
        "messages": {
          "messageValues": [
            {
              "message": "Respond in this JSON format:\n{\n  \"text_llm_generation_b\": \"<your answer here>\",\n  \"scorecard\": {\n    \"clarity\": 1–5,\n    \"relevance\": 1–5,\n    \"insightfulness\": 1–5,\n    \"actionability\": 1–5\n  }\n}\n"
            }
          ]
        },
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        784,
        0
      ],
      "id": "e3401b3d-408c-42b4-988d-77772f421ede",
      "name": "LLM Generation B"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.prompt }}\n\nRespond in this JSON format:\n\n{\n  \"text_llm_generation_a\": \"<your answer>\",\n  \"scorecard\": {\n    \"clarity\": 1–5,\n    \"relevance\": 1–5,\n    \"insightfulness\": 1–5,\n    \"actionability\": 1–5\n  }\n}\n\nAfter responding, evaluate your own output honestly. Be fair and self-critical — reserve 5s for excellent quality only.",
        "hasOutputParser": true,
        "messages": {
          "messageValues": [
            {
              "message": "Respond in this JSON format: {   \"text_llm_generation_a\": \"<your answer here>\",   \"scorecard\": {     \"clarity\": 1–5,     \"relevance\": 1–5,     \"insightfulness\": 1–5,     \"actionability\": 1–5   } }"
            }
          ]
        },
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        784,
        -448
      ],
      "id": "34f207e6-3777-45a8-87dd-76b25c8fad8a",
      "name": "LLM Generation A"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.prompt }}\n\nRespond in this JSON format:\n\n{\n  \"text_llm_generation_c\": \"<your answer>\",\n  \"scorecard\": {\n    \"clarity\": 1–5,\n    \"relevance\": 1–5,\n    \"insightfulness\": 1–5,\n    \"actionability\": 1–5\n  }\n}\n\nAfter responding, evaluate your own output honestly. Be fair and self-critical — reserve 5s for excellent quality only.\n",
        "hasOutputParser": true,
        "messages": {
          "messageValues": [
            {
              "message": "Respond in this JSON format:\n{\n  \"text_llm_generation_c\": \"<your answer here>\",\n  \"scorecard\": {\n    \"clarity\": 1–5,\n    \"relevance\": 1–5,\n    \"insightfulness\": 1–5,\n    \"actionability\": 1–5\n  }\n}\n"
            }
          ]
        },
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        800,
        448
      ],
      "id": "a85014e5-899b-4b4b-a97e-f4e10e4089dc",
      "name": "LLM Generation C"
    },
    {
      "parameters": {
        "jsCode": "const items = $items();\n\nconst responseA = items[0]?.json?.output || \"Missing response A\";\nconst responseB = items[1]?.json?.output || \"Missing response B\";\nconst responseC = items[2]?.json?.output || \"Missing response C\";\n\nreturn [{\n  json: {\n    responseA,\n    responseB,\n    responseC\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1888,
        0
      ],
      "id": "41e9b59a-e9f2-4d59-8369-a3081677a1dd",
      "name": "Manual Merge via Function"
    },
    {
      "parameters": {
        "content": "TODO: Swap one of the OpenAI models to something else",
        "height": 80
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        864,
        -560
      ],
      "typeVersion": 1,
      "id": "b92999a1-e596-4c93-a888-d7d2e1e336c5",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.voting_prompt }}",
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        2384,
        0
      ],
      "id": "562d0716-c731-4d56-bc3b-b0996a3f0fb1",
      "name": "Vote Node"
    },
    {
      "parameters": {
        "jsCode": "const { responseA, responseB, responseC } = $json;\n\nreturn [{\n  json: {\n    voting_prompt: `\nYou are a business insights assistant. Below are three responses to the same user query about churn analysis. Select the one that is the **clearest**, **most relevant**, and **offers the most insightful and actionable takeaway**.\n\nRespond with ONLY a single letter: A, B, or C.\n\n---\n\n[Response A]\n${responseA}\n\n---\n\n[Response B]\n${responseB}\n\n---\n\n[Response C]\n${responseC}\n\n---\n\nWhich response is best?\nYour answer:\n`\n  }\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2144,
        0
      ],
      "id": "e3f6b213-63aa-4f54-981b-842bf934f067",
      "name": "Prompt for vote"
    },
    {
      "parameters": {
        "jsCode": "return [{\n  json: {\n    vote: $json.text.replace(/\"/g, '').trim()\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2752,
        0
      ],
      "id": "efef8f52-c03f-4521-ab0b-a53f23c0b1c9",
      "name": "Clean vote"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "9e302425-a965-4f8d-b492-2ca857b05428",
              "name": "prompt",
              "value": "={{ $json.prompt }}",
              "type": "string"
            },
            {
              "id": "c483f4e3-205c-43d1-8f0b-5051091486c2",
              "name": "type",
              "value": "={{ $json.type }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        368,
        0
      ],
      "id": "0ef3576f-99a1-4a4c-be6c-85b73d3fd6fd",
      "name": "Prep prompt data"
    },
    {
      "parameters": {
        "inputSource": "passthrough"
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        -96,
        0
      ],
      "id": "de78cc17-3a97-4b76-b3f2-e4ba839091c5",
      "name": "When Executed by Another Workflow",
      "disabled": true
    },
    {
      "parameters": {
        "numberInputs": 3
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        1600,
        0
      ],
      "id": "32778af4-4df2-40b9-a87d-4084f3ea2339",
      "name": "Merge"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "8d280cd7-6326-43e0-a5b2-6efd81401482",
              "name": "prompt",
              "value": "\\nYou are an Insight Agent specializing in surfacing business-relevant insights from internal data sources.\\n\\n\\n\\n[User Query]\\nWhat changed in our Q2 churn compared to Q1?\\n\\n[Insight Type]\\nsummary\\n\\n[Instruction]\\nGenerate a concise summary of the key findings.\\n\\n[Your Response]\\n",
              "type": "string"
            },
            {
              "id": "0ee7e295-0ce1-47f9-bff3-961f911d7312",
              "name": "type",
              "value": "summary",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        160,
        240
      ],
      "id": "76bc9844-9cda-43dc-9ce9-d78f6375d2a0",
      "name": "Test Data"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        -96,
        240
      ],
      "id": "a7da28fb-0ad3-4bcc-9671-cbb23cd6878d",
      "name": "When clicking ‘Execute workflow’"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4o-mini"
        },
        "options": {
          "temperature": 0
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        2448,
        224
      ],
      "id": "d5000000-3e52-4ba9-b1f0-134c1def2b6b",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "KRyyaKtkymLK3YpM",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const voteLetter = $node[\"Clean vote\"].json.vote;\nconst voteIndex = voteLetter.charCodeAt(0) - 65;\nconst candidateCount = 3;\nconst outputs = [];\n\nfor (let i = 0; i < candidateCount; i++) {\n  const letter = String.fromCharCode(65 + i); // \"A\", \"B\", \"C\"\n  const label = `LLM Generation ${letter}`;\n  const llmJson = $node[label].json;\n  const inner = llmJson.output; // <-- inner wrapped structure\n\n  outputs.push({\n    json: {\n      output: inner[`text_llm_generation_${letter.toLowerCase()}`] || \"Missing output\",\n      scorecard: inner.scorecard || {},\n      source_node: label,\n      winner: i === voteIndex\n    }\n  });\n}\n\nreturn outputs;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2992,
        0
      ],
      "id": "3bcca915-c2e5-456c-8796-ca47ef834b25",
      "name": "Get vote output"
    },
    {
      "parameters": {
        "jsCode": "const json = $json.output;\n\nreturn [\n  {\n    json: {\n      output: json.text_llm_generation_b,\n      scorecard: json.scorecard || {},\n      source_node: \"LLM Generation B\"\n    }\n  }\n];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1152,
        0
      ],
      "id": "ed67d897-1a8d-4d24-a360-96f26057a181",
      "name": "Scorecard Parser B"
    },
    {
      "parameters": {
        "jsCode": "const json = $json.output;\n\nreturn [\n  {\n    json: {\n      output: json.text_llm_generation_a,\n      scorecard: json.scorecard || {},\n      source_node: \"LLM Generation A\"\n    }\n  }\n];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1152,
        -448
      ],
      "id": "9666e51e-9dd8-4587-b785-7ed132a7fd15",
      "name": "Scorecard Parser A"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"text_llm_generation_a\": \"In Q2, churn increased by 12% compared to Q1, primarily due to pricing changes and lower engagement among first-time users. The trend suggests a need to revisit onboarding flows and retention incentives for new signups.\",\n  \"scorecard\": {\n    \"clarity\": 5,\n    \"relevance\": 5,\n    \"insightfulness\": 4,\n    \"actionability\": 4\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        960,
        -256
      ],
      "id": "5777707a-e799-4689-b827-41972affbb8b",
      "name": "Structured Output Parser A"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"text_llm_generation_b\": \"In Q2, churn increased by 12% compared to Q1, primarily due to pricing changes and lower engagement among first-time users. The trend suggests a need to revisit onboarding flows and retention incentives for new signups.\",\n  \"scorecard\": {\n    \"clarity\": 5,\n    \"relevance\": 5,\n    \"insightfulness\": 4,\n    \"actionability\": 4\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        960,
        192
      ],
      "id": "bc071e74-d32d-4524-b81c-5f6d49b98d16",
      "name": "Structured Output Parser B"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-3.5-turbo",
          "mode": "list",
          "cachedResultName": "gpt-3.5-turbo"
        },
        "options": {
          "temperature": 0.7
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        752,
        -256
      ],
      "id": "bf1b5710-6452-4a87-8a31-5b6e20254cba",
      "name": "OpenAI Chat Model A",
      "credentials": {
        "openAiApi": {
          "id": "KRyyaKtkymLK3YpM",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-3.5-turbo",
          "mode": "list",
          "cachedResultName": "gpt-3.5-turbo"
        },
        "options": {
          "temperature": 0.9
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        752,
        192
      ],
      "id": "0998a07d-c28d-4035-a045-23478867f26f",
      "name": "OpenAI Chat Model B",
      "credentials": {
        "openAiApi": {
          "id": "KRyyaKtkymLK3YpM",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-3-haiku-20240307",
          "mode": "list",
          "cachedResultName": "Claude Haiku 3"
        },
        "options": {
          "temperature": 0.7
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        608,
        640
      ],
      "id": "170a049a-fe43-400f-ba59-fc9d93729993",
      "name": "Anthropic Chat Model C",
      "credentials": {
        "anthropicApi": {
          "id": "Wmz3AO5pPNbuodMG",
          "name": "Anthropic account"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"text_llm_generation_c\": \"In Q2, churn increased by 12% compared to Q1, primarily due to pricing changes and lower engagement among first-time users. The trend suggests a need to revisit onboarding flows and retention incentives for new signups.\",\n  \"scorecard\": {\n    \"clarity\": 5,\n    \"relevance\": 5,\n    \"insightfulness\": 4,\n    \"actionability\": 4\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        1008,
        640
      ],
      "id": "b61f28b8-7f94-4352-bbb9-41f0bc21a485",
      "name": "Structured Output Parser C"
    },
    {
      "parameters": {
        "jsCode": "const json = $json.output;\n\nreturn [\n  {\n    json: {\n      output: json.text_llm_generation_c,\n      scorecard: json.scorecard || {},\n      source_node: \"LLM Generation C\"\n    }\n  }\n];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1152,
        448
      ],
      "id": "915f84f7-b97d-4356-9496-695b2c5e507a",
      "name": "Scorecard Parser C"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-3.5-turbo",
          "mode": "list",
          "cachedResultName": "gpt-3.5-turbo"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        720,
        640
      ],
      "id": "81d66cb9-d981-4eb1-a87d-03ed2ad62caf",
      "name": "OpenAI Chat Model1",
      "credentials": {
        "openAiApi": {
          "id": "KRyyaKtkymLK3YpM",
          "name": "OpenAi account"
        }
      }
    }
  ],
  "pinData": {
    "LLM Generation A": [
      {
        "json": {
          "output": {
            "text_llm_generation_a": "In Q2, churn increased by 15% compared to Q1, primarily influenced by a rise in customer complaints and a reduction in customer support response times. Key demographics affected include small business clients, who reported dissatisfaction with service and pricing. Strategies to address these issues include enhancing customer support training and re-evaluating pricing models to improve retention rates.",
            "scorecard": {
              "clarity": 4,
              "relevance": 5,
              "insightfulness": 4,
              "actionability": 5
            }
          }
        }
      }
    ],
    "LLM Generation B": [
      {
        "json": {
          "output": {
            "text_llm_generation_b": "In Q2, the churn rate increased by 10% compared to Q1. Key factors contributing to this rise include a drop in customer satisfaction scores and an increase in service outages. Retention efforts implemented in Q2, such as targeted outreach and enhanced support, showed some positive effects but were insufficient to completely offset the churn increase. Recommendations include focusing on improving service reliability and customer engagement strategies to mitigate future churn.",
            "scorecard": {
              "clarity": 4,
              "relevance": 5,
              "insightfulness": 4,
              "actionability": 5
            }
          }
        }
      }
    ],
    "LLM Generation C": [
      {
        "json": {
          "output": {
            "text_llm_generation_c": "I don't have access to your company's internal churn data to provide specific insights about Q2 vs Q1 changes. To generate a meaningful summary of churn rate changes, I would need access to customer retention metrics, cancellation data, and relevant business context from your internal systems. Please provide the churn data or connect me to your data sources so I can analyze the quarter-over-quarter trends and identify key drivers of change.",
            "scorecard": {
              "clarity": 4,
              "relevance": 4,
              "insightfulness": 2,
              "actionability": 3
            }
          }
        }
      }
    ]
  },
  "connections": {
    "LLM Generation A": {
      "main": [
        [
          {
            "node": "Scorecard Parser A",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Generation B": {
      "main": [
        [
          {
            "node": "Scorecard Parser B",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Generation C": {
      "main": [
        [
          {
            "node": "Scorecard Parser C",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Manual Merge via Function": {
      "main": [
        [
          {
            "node": "Prompt for vote",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prompt for vote": {
      "main": [
        [
          {
            "node": "Vote Node",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Vote Node": {
      "main": [
        [
          {
            "node": "Clean vote",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Clean vote": {
      "main": [
        [
          {
            "node": "Get vote output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prep prompt data": {
      "main": [
        [
          {
            "node": "LLM Generation A",
            "type": "main",
            "index": 0
          },
          {
            "node": "LLM Generation B",
            "type": "main",
            "index": 0
          },
          {
            "node": "LLM Generation C",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When Executed by Another Workflow": {
      "main": [
        [
          {
            "node": "Prep prompt data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Test Data": {
      "main": [
        [
          {
            "node": "Prep prompt data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When clicking ‘Execute workflow’": {
      "main": [
        [
          {
            "node": "Test Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "Manual Merge via Function",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Vote Node",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Get vote output": {
      "main": [
        []
      ]
    },
    "Structured Output Parser A": {
      "ai_outputParser": [
        [
          {
            "node": "LLM Generation A",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser B": {
      "ai_outputParser": [
        [
          {
            "node": "LLM Generation B",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model A": {
      "ai_languageModel": [
        [
          {
            "node": "LLM Generation A",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model B": {
      "ai_languageModel": [
        [
          {
            "node": "LLM Generation B",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model C": {
      "ai_languageModel": [
        []
      ]
    },
    "Structured Output Parser C": {
      "ai_outputParser": [
        [
          {
            "node": "LLM Generation C",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Scorecard Parser B": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Scorecard Parser A": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Scorecard Parser C": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "OpenAI Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "LLM Generation C",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "59ba7f47-0343-4ebf-a213-fb75b3457ed0",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "0e1664e1c576ef52797abfb36899a10b94b3f051cdf548d41e9d265459c6a618"
  },
  "id": "vRjzDA3odWrYEsYa",
  "tags": [
    {
      "updatedAt": "2025-06-13T00:44:28.800Z",
      "createdAt": "2025-06-13T00:44:28.800Z",
      "id": "HMfvMejmdgx6xPHF",
      "name": "PromptOS"
    }
  ]
}